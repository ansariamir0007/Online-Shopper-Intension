{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"online_shoppers_intention.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
       "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
       "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
       "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
       "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.315166</td>\n",
       "      <td>80.818611</td>\n",
       "      <td>0.503569</td>\n",
       "      <td>34.472398</td>\n",
       "      <td>31.731468</td>\n",
       "      <td>1194.746220</td>\n",
       "      <td>0.022191</td>\n",
       "      <td>0.043073</td>\n",
       "      <td>5.889258</td>\n",
       "      <td>0.061427</td>\n",
       "      <td>2.124006</td>\n",
       "      <td>2.357097</td>\n",
       "      <td>3.147364</td>\n",
       "      <td>4.069586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.321784</td>\n",
       "      <td>176.779107</td>\n",
       "      <td>1.270156</td>\n",
       "      <td>140.749294</td>\n",
       "      <td>44.475503</td>\n",
       "      <td>1913.669288</td>\n",
       "      <td>0.048488</td>\n",
       "      <td>0.048597</td>\n",
       "      <td>18.568437</td>\n",
       "      <td>0.198917</td>\n",
       "      <td>0.911325</td>\n",
       "      <td>1.717277</td>\n",
       "      <td>2.401591</td>\n",
       "      <td>4.025169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>184.137500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>598.936905</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>0.025156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>93.256250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1464.157213</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>3398.750000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2549.375000</td>\n",
       "      <td>705.000000</td>\n",
       "      <td>63973.522230</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>361.763742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Administrative  Administrative_Duration  Informational  \\\n",
       "count    12330.000000             12330.000000   12330.000000   \n",
       "mean         2.315166                80.818611       0.503569   \n",
       "std          3.321784               176.779107       1.270156   \n",
       "min          0.000000                 0.000000       0.000000   \n",
       "25%          0.000000                 0.000000       0.000000   \n",
       "50%          1.000000                 7.500000       0.000000   \n",
       "75%          4.000000                93.256250       0.000000   \n",
       "max         27.000000              3398.750000      24.000000   \n",
       "\n",
       "       Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "count            12330.000000    12330.000000             12330.000000   \n",
       "mean                34.472398       31.731468              1194.746220   \n",
       "std                140.749294       44.475503              1913.669288   \n",
       "min                  0.000000        0.000000                 0.000000   \n",
       "25%                  0.000000        7.000000               184.137500   \n",
       "50%                  0.000000       18.000000               598.936905   \n",
       "75%                  0.000000       38.000000              1464.157213   \n",
       "max               2549.375000      705.000000             63973.522230   \n",
       "\n",
       "        BounceRates     ExitRates    PageValues    SpecialDay  \\\n",
       "count  12330.000000  12330.000000  12330.000000  12330.000000   \n",
       "mean       0.022191      0.043073      5.889258      0.061427   \n",
       "std        0.048488      0.048597     18.568437      0.198917   \n",
       "min        0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.014286      0.000000      0.000000   \n",
       "50%        0.003112      0.025156      0.000000      0.000000   \n",
       "75%        0.016813      0.050000      0.000000      0.000000   \n",
       "max        0.200000      0.200000    361.763742      1.000000   \n",
       "\n",
       "       OperatingSystems       Browser        Region   TrafficType  \n",
       "count      12330.000000  12330.000000  12330.000000  12330.000000  \n",
       "mean           2.124006      2.357097      3.147364      4.069586  \n",
       "std            0.911325      1.717277      2.401591      4.025169  \n",
       "min            1.000000      1.000000      1.000000      1.000000  \n",
       "25%            2.000000      2.000000      1.000000      2.000000  \n",
       "50%            2.000000      2.000000      3.000000      2.000000  \n",
       "75%            3.000000      2.000000      4.000000      4.000000  \n",
       "max            8.000000     13.000000      9.000000     20.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Administrative               int64\n",
       "Administrative_Duration    float64\n",
       "Informational                int64\n",
       "Informational_Duration     float64\n",
       "ProductRelated               int64\n",
       "ProductRelated_Duration    float64\n",
       "BounceRates                float64\n",
       "ExitRates                  float64\n",
       "PageValues                 float64\n",
       "SpecialDay                 float64\n",
       "Month                       object\n",
       "OperatingSystems             int64\n",
       "Browser                      int64\n",
       "Region                       int64\n",
       "TrafficType                  int64\n",
       "VisitorType                 object\n",
       "Weekend                       bool\n",
       "Revenue                       bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>...</th>\n",
       "      <th>Month_Jul</th>\n",
       "      <th>Month_June</th>\n",
       "      <th>Month_Mar</th>\n",
       "      <th>Month_May</th>\n",
       "      <th>Month_Nov</th>\n",
       "      <th>Month_Oct</th>\n",
       "      <th>Month_Sep</th>\n",
       "      <th>VisitorType_New_Visitor</th>\n",
       "      <th>VisitorType_Other</th>\n",
       "      <th>VisitorType_Returning_Visitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay  ...  Month_Jul  Month_June  \\\n",
       "0         0.20       0.20         0.0         0.0  ...          0           0   \n",
       "1         0.00       0.10         0.0         0.0  ...          0           0   \n",
       "2         0.20       0.20         0.0         0.0  ...          0           0   \n",
       "3         0.05       0.14         0.0         0.0  ...          0           0   \n",
       "4         0.02       0.05         0.0         0.0  ...          0           0   \n",
       "\n",
       "   Month_Mar  Month_May  Month_Nov  Month_Oct  Month_Sep  \\\n",
       "0          0          0          0          0          0   \n",
       "1          0          0          0          0          0   \n",
       "2          0          0          0          0          0   \n",
       "3          0          0          0          0          0   \n",
       "4          0          0          0          0          0   \n",
       "\n",
       "   VisitorType_New_Visitor  VisitorType_Other  VisitorType_Returning_Visitor  \n",
       "0                        0                  0                              1  \n",
       "1                        0                  0                              1  \n",
       "2                        0                  0                              1  \n",
       "3                        0                  0                              1  \n",
       "4                        0                  0                              1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.get_dummies(data=df, columns=['Month', 'VisitorType'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Direct Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Models(x_train,y_train,x_test,y_test):\n",
    "    \n",
    "    x_train=x_train\n",
    "    y_train=y_train\n",
    "    x_test=x_test\n",
    "    y_test=y_test\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn import metrics\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"LOGISTIC REGRESSION\")\n",
    "    lg = LogisticRegression()\n",
    "    lg.fit(x_train, y_train)\n",
    "    ypred = lg.predict(x_test)\n",
    "    confusion_matrix = confusion_matrix(y_test, ypred)\n",
    "    print(\"Confusion matrix for Logistic:\",confusion_matrix)\n",
    "    accuracy_score = accuracy_score(y_test, ypred)\n",
    "    print(\"Accuracy score for Logistic:\",accuracy_score)\n",
    "    print(\"Classification Report for Logistic report\",classification_report(y_test, ypred, target_names=['Yes', 'No']))\n",
    "\n",
    "    print(\"DECISION TREE\")\n",
    "    dt=DecisionTreeClassifier(criterion = 'gini',max_depth=4)\n",
    "    dt.fit(x_train,y_train)\n",
    "    ypred2=dt.predict(x_test)\n",
    "    cm2=metrics.confusion_matrix(y_test,ypred2)\n",
    "    print(\"Confusion matrix for Decision Tree:\",cm2)\n",
    "    acc2=metrics.accuracy_score(y_test,ypred2)\n",
    "    print(\"Accuracy score for Decision Tree:\",acc2)\n",
    "    cr2=metrics.classification_report(y_test,ypred2)\n",
    "    print(\"Classification Report for Logistic report\",cr2)\n",
    "\n",
    "    print(\"Naive Bayes Gaussian\")\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(x_train, y_train)\n",
    "    ypred3=gnb.predict(x_test)\n",
    "    cm3=metrics.confusion_matrix(y_test,ypred3)\n",
    "    print(\"Confusion matrix for Gaussian:\",cm3)\n",
    "    acc3=metrics.accuracy_score(y_test,ypred3)\n",
    "    print(\"Accuracy score for Gaussian:\",acc3)\n",
    "    cr3=metrics.classification_report(y_test,ypred3)\n",
    "    print(\"Classification Report for Gaussian\",cr3)\n",
    "\n",
    "    print(\"Naive Bayes Bernoulli\")\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(x_train, y_train)\n",
    "    ypred4=bnb.predict(x_test)\n",
    "    cm4=metrics.confusion_matrix(y_test,ypred4)\n",
    "    print(\"Confusion matrix for Bernoulli\",cm4)\n",
    "    acc4=metrics.accuracy_score(y_test,ypred4)\n",
    "    print(\"Accuracy score for Bernoulli:\",acc4)\n",
    "    cr4=metrics.classification_report(y_test,ypred4)\n",
    "    print(\"Classification Report for Bernoulli:\",cr4)\n",
    "\n",
    "    print(\"Naive Bayes Multinomial\")\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(x_train, y_train)\n",
    "    ypred5=mnb.predict(x_test)\n",
    "    cm5=metrics.confusion_matrix(y_test,ypred5)\n",
    "    print(\"Confusion matrix for Bernoulli:\",cm5)\n",
    "    acc=metrics.accuracy_score(y_test,ypred5)\n",
    "    print(\"Accuracy score for Bernoulli:\",acc)\n",
    "    cr5=metrics.classification_report(y_test,ypred5)\n",
    "    print(\"Classification Report for Bernoulli:\",cr5)\n",
    "    \n",
    "    print(\"Support Vector Machine\")\n",
    "    svm=SVC()\n",
    "    svm.fit(x_train, y_train)\n",
    "    ypred6=svm.predict(x_test)\n",
    "    cm6=metrics.confusion_matrix(y_test,ypred6)\n",
    "    print(\"Confusion matrix for SVM :\",cm6)\n",
    "    acc=metrics.accuracy_score(y_test,ypred6)\n",
    "    print(\"Accuracy score for SVM :\",acc)\n",
    "    cr6=metrics.classification_report(y_test,ypred6)\n",
    "    print(\"Classification Report for SVM :\",cr6)\n",
    "    \n",
    "    print(\"Random Forest\")\n",
    "    rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "    rf.fit(x_train, y_train)\n",
    "    ypred7=svm.predict(x_test)\n",
    "    cm7=metrics.confusion_matrix(y_test,ypred7)\n",
    "    print(\"Confusion matrix for Random Forest :\",cm7)\n",
    "    acc=metrics.accuracy_score(y_test,ypred7)\n",
    "    print(\"Accuracy score for Random Forest :\",acc)\n",
    "    cr7=metrics.classification_report(y_test,ypred7)\n",
    "    print(\"Classification Report for Random Forest :\",cr7)\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = df2.drop(['Revenue'],axis=1)\n",
    "y = df2['Revenue']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for Logistic: [[3003   74]\n",
      " [ 393  229]]\n",
      "Accuracy score for Logistic: 0.8737496620708299\n",
      "Classification Report for Logistic report               precision    recall  f1-score   support\n",
      "\n",
      "         Yes       0.88      0.98      0.93      3077\n",
      "          No       0.76      0.37      0.50       622\n",
      "\n",
      "    accuracy                           0.87      3699\n",
      "   macro avg       0.82      0.67      0.71      3699\n",
      "weighted avg       0.86      0.87      0.86      3699\n",
      "\n",
      "DECISION TREE\n",
      "Confusion matrix for Decision Tree: [[2947  130]\n",
      " [ 275  347]]\n",
      "Accuracy score for Decision Tree: 0.8905109489051095\n",
      "Classification Report for Logistic report               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.96      0.94      3077\n",
      "        True       0.73      0.56      0.63       622\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.82      0.76      0.78      3699\n",
      "weighted avg       0.88      0.89      0.88      3699\n",
      "\n",
      "Naive Bayes Gaussian\n",
      "Confusion matrix for Gaussian: [[2540  537]\n",
      " [ 239  383]]\n",
      "Accuracy score for Gaussian: 0.7902135712354691\n",
      "Classification Report for Gaussian               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.83      0.87      3077\n",
      "        True       0.42      0.62      0.50       622\n",
      "\n",
      "    accuracy                           0.79      3699\n",
      "   macro avg       0.67      0.72      0.68      3699\n",
      "weighted avg       0.83      0.79      0.81      3699\n",
      "\n",
      "Naive Bayes Bernoulli\n",
      "Confusion matrix for Bernoulli [[2778  299]\n",
      " [ 275  347]]\n",
      "Accuracy score for Bernoulli: 0.8448229251148959\n",
      "Classification Report for Bernoulli:               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.90      0.91      3077\n",
      "        True       0.54      0.56      0.55       622\n",
      "\n",
      "    accuracy                           0.84      3699\n",
      "   macro avg       0.72      0.73      0.73      3699\n",
      "weighted avg       0.85      0.84      0.85      3699\n",
      "\n",
      "Naive Bayes Multinomial\n",
      "Confusion matrix for Bernoulli: [[2828  249]\n",
      " [ 256  366]]\n",
      "Accuracy score for Bernoulli: 0.8634766153014328\n",
      "Classification Report for Bernoulli:               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.92      0.92      3077\n",
      "        True       0.60      0.59      0.59       622\n",
      "\n",
      "    accuracy                           0.86      3699\n",
      "   macro avg       0.76      0.75      0.75      3699\n",
      "weighted avg       0.86      0.86      0.86      3699\n",
      "\n",
      "Support Vector Machine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for SVM : [[3077    0]\n",
      " [ 622    0]]\n",
      "Accuracy score for SVM : 0.8318464449851312\n",
      "Classification Report for SVM :               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      1.00      0.91      3077\n",
      "        True       0.00      0.00      0.00       622\n",
      "\n",
      "    accuracy                           0.83      3699\n",
      "   macro avg       0.42      0.50      0.45      3699\n",
      "weighted avg       0.69      0.83      0.76      3699\n",
      "\n",
      "Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for Random Forest : [[3077    0]\n",
      " [ 622    0]]\n",
      "Accuracy score for Random Forest : 0.8318464449851312\n",
      "Classification Report for Random Forest :               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      1.00      0.91      3077\n",
      "        True       0.00      0.00      0.00       622\n",
      "\n",
      "    accuracy                           0.83      3699\n",
      "   macro avg       0.42      0.50      0.45      3699\n",
      "weighted avg       0.69      0.83      0.76      3699\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Models(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scale=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Data With Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=scale.fit_transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.DataFrame(dfs,columns=df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>...</th>\n",
       "      <th>Month_Jul</th>\n",
       "      <th>Month_June</th>\n",
       "      <th>Month_Mar</th>\n",
       "      <th>Month_May</th>\n",
       "      <th>Month_Nov</th>\n",
       "      <th>Month_Oct</th>\n",
       "      <th>Month_Sep</th>\n",
       "      <th>VisitorType_New_Visitor</th>\n",
       "      <th>VisitorType_Other</th>\n",
       "      <th>VisitorType_Returning_Visitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0             0.0                      0.0            0.0   \n",
       "1             0.0                      0.0            0.0   \n",
       "2             0.0                      0.0            0.0   \n",
       "3             0.0                      0.0            0.0   \n",
       "4             0.0                      0.0            0.0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0        0.001418                 0.000000   \n",
       "1                     0.0        0.002837                 0.001000   \n",
       "2                     0.0        0.001418                 0.000000   \n",
       "3                     0.0        0.002837                 0.000042   \n",
       "4                     0.0        0.014184                 0.009809   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay  ...  Month_Jul  Month_June  \\\n",
       "0         1.00       1.00         0.0         0.0  ...        0.0         0.0   \n",
       "1         0.00       0.50         0.0         0.0  ...        0.0         0.0   \n",
       "2         1.00       1.00         0.0         0.0  ...        0.0         0.0   \n",
       "3         0.25       0.70         0.0         0.0  ...        0.0         0.0   \n",
       "4         0.10       0.25         0.0         0.0  ...        0.0         0.0   \n",
       "\n",
       "   Month_Mar  Month_May  Month_Nov  Month_Oct  Month_Sep  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   VisitorType_New_Visitor  VisitorType_Other  VisitorType_Returning_Visitor  \n",
       "0                      0.0                0.0                            1.0  \n",
       "1                      0.0                0.0                            1.0  \n",
       "2                      0.0                0.0                            1.0  \n",
       "3                      0.0                0.0                            1.0  \n",
       "4                      0.0                0.0                            1.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Model on Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df3.drop(['Revenue'],axis=1)\n",
    "y=df3['Revenue']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "Confusion matrix for Logistic: [[3031   46]\n",
      " [ 476  146]]\n",
      "Accuracy score for Logistic: 0.8588807785888077\n",
      "Classification Report for Logistic report               precision    recall  f1-score   support\n",
      "\n",
      "         Yes       0.86      0.99      0.92      3077\n",
      "          No       0.76      0.23      0.36       622\n",
      "\n",
      "    accuracy                           0.86      3699\n",
      "   macro avg       0.81      0.61      0.64      3699\n",
      "weighted avg       0.85      0.86      0.83      3699\n",
      "\n",
      "DECISION TREE\n",
      "Confusion matrix for Decision Tree: [[2947  130]\n",
      " [ 275  347]]\n",
      "Accuracy score for Decision Tree: 0.8905109489051095\n",
      "Classification Report for Logistic report               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.96      0.94      3077\n",
      "         1.0       0.73      0.56      0.63       622\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.82      0.76      0.78      3699\n",
      "weighted avg       0.88      0.89      0.88      3699\n",
      "\n",
      "Naive Bayes Gaussian\n",
      "Confusion matrix for Gaussian: [[2044 1033]\n",
      " [ 126  496]]\n",
      "Accuracy score for Gaussian: 0.6866720735333874\n",
      "Classification Report for Gaussian               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.66      0.78      3077\n",
      "         1.0       0.32      0.80      0.46       622\n",
      "\n",
      "    accuracy                           0.69      3699\n",
      "   macro avg       0.63      0.73      0.62      3699\n",
      "weighted avg       0.84      0.69      0.73      3699\n",
      "\n",
      "Naive Bayes Bernoulli\n",
      "Confusion matrix for Bernoulli [[2781  296]\n",
      " [ 283  339]]\n",
      "Accuracy score for Bernoulli: 0.8434712084347121\n",
      "Classification Report for Bernoulli:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.90      0.91      3077\n",
      "         1.0       0.53      0.55      0.54       622\n",
      "\n",
      "    accuracy                           0.84      3699\n",
      "   macro avg       0.72      0.72      0.72      3699\n",
      "weighted avg       0.84      0.84      0.84      3699\n",
      "\n",
      "Naive Bayes Multinomial\n",
      "Confusion matrix for Bernoulli: [[3074    3]\n",
      " [ 606   16]]\n",
      "Accuracy score for Bernoulli: 0.8353609083536091\n",
      "Classification Report for Bernoulli:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      1.00      0.91      3077\n",
      "         1.0       0.84      0.03      0.05       622\n",
      "\n",
      "    accuracy                           0.84      3699\n",
      "   macro avg       0.84      0.51      0.48      3699\n",
      "weighted avg       0.84      0.84      0.77      3699\n",
      "\n",
      "Support Vector Machine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Amir\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for SVM : [[3073    4]\n",
      " [ 606   16]]\n",
      "Accuracy score for SVM : 0.8350905650175723\n",
      "Classification Report for SVM :               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      1.00      0.91      3077\n",
      "         1.0       0.80      0.03      0.05       622\n",
      "\n",
      "    accuracy                           0.84      3699\n",
      "   macro avg       0.82      0.51      0.48      3699\n",
      "weighted avg       0.83      0.84      0.77      3699\n",
      "\n",
      "Random Forest\n",
      "Confusion matrix for Random Forest : [[3073    4]\n",
      " [ 606   16]]\n",
      "Accuracy score for Random Forest : 0.8350905650175723\n",
      "Classification Report for Random Forest :               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      1.00      0.91      3077\n",
      "         1.0       0.80      0.03      0.05       622\n",
      "\n",
      "    accuracy                           0.84      3699\n",
      "   macro avg       0.82      0.51      0.48      3699\n",
      "weighted avg       0.83      0.84      0.77      3699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Models(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Data without Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsx=scale.fit_transform(df2.drop(['Revenue'],axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appling Model on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dfsx\n",
    "y=df2['Revenue']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "Confusion matrix for Logistic: [[3031   46]\n",
      " [ 476  146]]\n",
      "Accuracy score for Logistic: 0.8588807785888077\n",
      "Classification Report for Logistic report               precision    recall  f1-score   support\n",
      "\n",
      "         Yes       0.86      0.99      0.92      3077\n",
      "          No       0.76      0.23      0.36       622\n",
      "\n",
      "    accuracy                           0.86      3699\n",
      "   macro avg       0.81      0.61      0.64      3699\n",
      "weighted avg       0.85      0.86      0.83      3699\n",
      "\n",
      "DECISION TREE\n",
      "Confusion matrix for Decision Tree: [[2947  130]\n",
      " [ 275  347]]\n",
      "Accuracy score for Decision Tree: 0.8905109489051095\n",
      "Classification Report for Logistic report               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.96      0.94      3077\n",
      "        True       0.73      0.56      0.63       622\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.82      0.76      0.78      3699\n",
      "weighted avg       0.88      0.89      0.88      3699\n",
      "\n",
      "Naive Bayes Gaussian\n",
      "Confusion matrix for Gaussian: [[2044 1033]\n",
      " [ 126  496]]\n",
      "Accuracy score for Gaussian: 0.6866720735333874\n",
      "Classification Report for Gaussian               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.66      0.78      3077\n",
      "        True       0.32      0.80      0.46       622\n",
      "\n",
      "    accuracy                           0.69      3699\n",
      "   macro avg       0.63      0.73      0.62      3699\n",
      "weighted avg       0.84      0.69      0.73      3699\n",
      "\n",
      "Naive Bayes Bernoulli\n",
      "Confusion matrix for Bernoulli [[2781  296]\n",
      " [ 283  339]]\n",
      "Accuracy score for Bernoulli: 0.8434712084347121\n",
      "Classification Report for Bernoulli:               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.90      0.91      3077\n",
      "        True       0.53      0.55      0.54       622\n",
      "\n",
      "    accuracy                           0.84      3699\n",
      "   macro avg       0.72      0.72      0.72      3699\n",
      "weighted avg       0.84      0.84      0.84      3699\n",
      "\n",
      "Naive Bayes Multinomial\n",
      "Confusion matrix for Bernoulli: [[3074    3]\n",
      " [ 606   16]]\n",
      "Accuracy score for Bernoulli: 0.8353609083536091\n",
      "Classification Report for Bernoulli:               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      1.00      0.91      3077\n",
      "        True       0.84      0.03      0.05       622\n",
      "\n",
      "    accuracy                           0.84      3699\n",
      "   macro avg       0.84      0.51      0.48      3699\n",
      "weighted avg       0.84      0.84      0.77      3699\n",
      "\n",
      "Support Vector Machine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Amir\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for SVM : [[3073    4]\n",
      " [ 606   16]]\n",
      "Accuracy score for SVM : 0.8350905650175723\n",
      "Classification Report for SVM :               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      1.00      0.91      3077\n",
      "        True       0.80      0.03      0.05       622\n",
      "\n",
      "    accuracy                           0.84      3699\n",
      "   macro avg       0.82      0.51      0.48      3699\n",
      "weighted avg       0.83      0.84      0.77      3699\n",
      "\n",
      "Random Forest\n",
      "Confusion matrix for Random Forest : [[3073    4]\n",
      " [ 606   16]]\n",
      "Accuracy score for Random Forest : 0.8350905650175723\n",
      "Classification Report for Random Forest :               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      1.00      0.91      3077\n",
      "        True       0.80      0.03      0.05       622\n",
      "\n",
      "    accuracy                           0.84      3699\n",
      "   macro avg       0.82      0.51      0.48      3699\n",
      "weighted avg       0.83      0.84      0.77      3699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Models(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\amir\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\amir\\anaconda3\\lib\\site-packages (from imblearn) (0.5.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\amir\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.14.0)\n",
      "Requirement already satisfied: scipy>=0.17 in c:\\users\\amir\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21 in c:\\users\\amir\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.21.3)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\amir\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.16.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt=SMOTE()\n",
    "x_train,y_train=smt.fit_sample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14690, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14690,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3699, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3699,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apppling Model on OverSampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "Confusion matrix for Logistic: [[2578  499]\n",
      " [ 166  456]]\n",
      "Accuracy score for Logistic: 0.8202216815355502\n",
      "Classification Report for Logistic report               precision    recall  f1-score   support\n",
      "\n",
      "         Yes       0.94      0.84      0.89      3077\n",
      "          No       0.48      0.73      0.58       622\n",
      "\n",
      "    accuracy                           0.82      3699\n",
      "   macro avg       0.71      0.79      0.73      3699\n",
      "weighted avg       0.86      0.82      0.83      3699\n",
      "\n",
      "DECISION TREE\n",
      "Confusion matrix for Decision Tree: [[2702  375]\n",
      " [ 123  499]]\n",
      "Accuracy score for Decision Tree: 0.8653690186536902\n",
      "Classification Report for Logistic report               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.88      0.92      3077\n",
      "        True       0.57      0.80      0.67       622\n",
      "\n",
      "    accuracy                           0.87      3699\n",
      "   macro avg       0.76      0.84      0.79      3699\n",
      "weighted avg       0.89      0.87      0.87      3699\n",
      "\n",
      "Naive Bayes Gaussian\n",
      "Confusion matrix for Gaussian:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [[1424 1653]\n",
      " [  63  559]]\n",
      "Accuracy score for Gaussian: 0.5360908353609084\n",
      "Classification Report for Gaussian               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.46      0.62      3077\n",
      "        True       0.25      0.90      0.39       622\n",
      "\n",
      "    accuracy                           0.54      3699\n",
      "   macro avg       0.61      0.68      0.51      3699\n",
      "weighted avg       0.84      0.54      0.59      3699\n",
      "\n",
      "Naive Bayes Bernoulli\n",
      "Confusion matrix for Bernoulli [[2480  597]\n",
      " [ 197  425]]\n",
      "Accuracy score for Bernoulli: 0.7853473911868073\n",
      "Classification Report for Bernoulli:               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.81      0.86      3077\n",
      "        True       0.42      0.68      0.52       622\n",
      "\n",
      "    accuracy                           0.79      3699\n",
      "   macro avg       0.67      0.74      0.69      3699\n",
      "weighted avg       0.84      0.79      0.80      3699\n",
      "\n",
      "Naive Bayes Multinomial\n",
      "Confusion matrix for Bernoulli: [[1952 1125]\n",
      " [ 182  440]]\n",
      "Accuracy score for Bernoulli: 0.6466612597999459\n",
      "Classification Report for Bernoulli:               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.63      0.75      3077\n",
      "        True       0.28      0.71      0.40       622\n",
      "\n",
      "    accuracy                           0.65      3699\n",
      "   macro avg       0.60      0.67      0.58      3699\n",
      "weighted avg       0.81      0.65      0.69      3699\n",
      "\n",
      "Support Vector Machine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for SVM : [[2309  768]\n",
      " [ 160  462]]\n",
      "Accuracy score for SVM : 0.7491213841578805\n",
      "Classification Report for SVM :               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.75      0.83      3077\n",
      "        True       0.38      0.74      0.50       622\n",
      "\n",
      "    accuracy                           0.75      3699\n",
      "   macro avg       0.66      0.75      0.67      3699\n",
      "weighted avg       0.84      0.75      0.78      3699\n",
      "\n",
      "Random Forest\n",
      "Confusion matrix for Random Forest : [[2309  768]\n",
      " [ 160  462]]\n",
      "Accuracy score for Random Forest : 0.7491213841578805\n",
      "Classification Report for Random Forest :               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.75      0.83      3077\n",
      "        True       0.38      0.74      0.50       622\n",
      "\n",
      "    accuracy                           0.75      3699\n",
      "   macro avg       0.66      0.75      0.67      3699\n",
      "weighted avg       0.84      0.75      0.78      3699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Models(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension Reduction Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Principle Component Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.51373266e-04,  3.30627372e-02,  2.57873478e-04,\n",
       "         2.56677766e-02,  1.99879817e-02,  9.98923288e-01,\n",
       "        -4.67794517e-06, -6.40286469e-06,  5.13763608e-04,\n",
       "        -3.79977595e-06,  1.39429026e-06, -6.68174444e-06,\n",
       "        -4.15016614e-05, -7.65012197e-05,  1.63065234e-06,\n",
       "         7.54448608e-07, -3.17711444e-06, -2.95355246e-06,\n",
       "         2.20979238e-07,  1.12149723e-07, -1.61295944e-05,\n",
       "        -1.58576503e-05,  3.73630915e-05, -9.22696268e-07,\n",
       "         5.89938814e-07, -2.08925807e-05, -1.17454385e-06,\n",
       "         2.20671245e-05],\n",
       "       [ 9.99615234e-03,  9.65554215e-01,  2.06013879e-03,\n",
       "         2.56993525e-01, -6.55061705e-03, -3.84408323e-02,\n",
       "        -2.36530905e-05, -3.52704657e-05,  5.87367835e-03,\n",
       "        -7.76740106e-05, -5.91233232e-05, -1.69968168e-04,\n",
       "         4.41593433e-05, -9.45105905e-05,  4.35540838e-05,\n",
       "         2.78726554e-05,  1.02148669e-05, -2.24059120e-05,\n",
       "         5.42261378e-08, -2.10882828e-05,  2.50062800e-05,\n",
       "        -4.50137405e-05, -8.35374770e-05,  7.57015877e-05,\n",
       "         3.31957961e-05,  1.39112614e-04,  2.04812675e-07,\n",
       "        -1.39317427e-04],\n",
       "       [-8.60476848e-04, -2.57799482e-01,  4.44489611e-03,\n",
       "         9.66037209e-01, -5.33313963e-03, -1.61836155e-02,\n",
       "         6.59375165e-06,  8.57912118e-06, -6.08434836e-04,\n",
       "         3.77773027e-06, -5.80966347e-05, -1.74298696e-04,\n",
       "        -3.46788264e-04, -3.78238808e-04,  5.98904725e-05,\n",
       "        -1.46911367e-05,  4.54666337e-05, -2.40702736e-06,\n",
       "         2.26824562e-05, -1.16102177e-05,  4.69677608e-05,\n",
       "        -1.08632676e-05, -4.31476024e-05, -1.69373879e-05,\n",
       "        -1.54602108e-05, -6.99004304e-05, -2.95948977e-06,\n",
       "         7.28599202e-05],\n",
       "       [-3.52979333e-02, -3.58391864e-03, -5.92333310e-03,\n",
       "        -6.16137560e-03, -9.97391505e-01,  2.02895043e-02,\n",
       "         2.10735680e-04,  3.46091991e-04, -5.86359514e-02,\n",
       "        -7.59005929e-05, -1.37675681e-04,  9.41945412e-04,\n",
       "         2.00738724e-03,  4.21878554e-03, -3.93967691e-04,\n",
       "        -3.47558015e-04,  5.40193033e-04,  1.92149685e-04,\n",
       "        -2.85015187e-04, -1.65872807e-04,  1.30463074e-03,\n",
       "         5.53998908e-04, -1.43095151e-03, -3.31263749e-04,\n",
       "        -3.03110995e-05,  5.56669531e-04,  8.23740108e-05,\n",
       "        -6.39043542e-04],\n",
       "       [ 6.48418152e-03, -6.15320944e-03,  5.62687807e-04,\n",
       "        -1.31662186e-03, -5.88432791e-02,  8.97600379e-04,\n",
       "        -2.58930223e-04, -3.78248637e-04,  9.98200555e-01,\n",
       "        -6.35592311e-04,  9.38026519e-04,  4.49797308e-03,\n",
       "         1.89243506e-03,  3.74274538e-03,  2.12959798e-04,\n",
       "        -4.33571438e-05,  4.49246218e-04, -1.75010454e-04,\n",
       "        -2.08741265e-04, -1.76051613e-04, -6.82887084e-04,\n",
       "        -2.08236904e-04,  5.90320974e-04,  2.99241861e-04,\n",
       "         1.55475411e-04,  2.06066110e-03,  2.63183185e-04,\n",
       "        -2.32384428e-03],\n",
       "       [-1.76475278e-02,  2.23255634e-04, -4.47641287e-03,\n",
       "         5.10468914e-04,  5.19987576e-03, -3.18024986e-05,\n",
       "         8.57372782e-04,  8.30593925e-04, -3.71187199e-03,\n",
       "         2.59780907e-03,  4.65439211e-02,  5.96480849e-02,\n",
       "         4.44771084e-02,  9.95849641e-01, -2.66201242e-04,\n",
       "        -1.14732423e-03,  1.06469504e-04, -1.28384758e-03,\n",
       "        -7.37837933e-04,  2.28897682e-04, -9.01355927e-03,\n",
       "         6.57596055e-03,  6.40554799e-03,  5.07001620e-04,\n",
       "        -1.64130834e-03, -2.50000124e-03,  4.31473833e-03,\n",
       "        -1.81473708e-03],\n",
       "       [-9.66983438e-01,  9.75180029e-03, -6.49165367e-02,\n",
       "         2.13064027e-03,  3.34992471e-02, -4.16041185e-04,\n",
       "         2.26092001e-03,  3.08340196e-03,  8.93302238e-03,\n",
       "         5.45714683e-03, -6.96500959e-03, -8.81634877e-03,\n",
       "        -2.42775115e-01, -5.94396968e-03, -2.42881263e-03,\n",
       "        -2.21126583e-03, -1.14119595e-03,  1.84137150e-03,\n",
       "        -2.02394628e-04, -4.00291683e-04,  2.38320124e-03,\n",
       "         5.95501688e-03,  4.01101951e-03, -5.95394055e-03,\n",
       "        -4.28152050e-03, -8.35541489e-03, -8.18586137e-04,\n",
       "         9.17400103e-03],\n",
       "       [-2.40131144e-01,  2.33139690e-03, -2.22600728e-02,\n",
       "         9.14132946e-04,  1.04364792e-02, -1.10536775e-04,\n",
       "         1.77165194e-04,  3.12969287e-04, -3.50316933e-05,\n",
       "        -2.96804158e-04,  3.43555680e-02,  1.30087886e-01,\n",
       "         9.59315825e-01, -5.66680414e-02, -1.28686854e-03,\n",
       "         3.30325138e-04,  6.76589626e-03, -7.75617573e-04,\n",
       "         1.86857941e-03,  7.14472448e-05, -1.97589833e-03,\n",
       "        -5.81255448e-04, -4.44965126e-03, -1.44816485e-03,\n",
       "         1.94339416e-04,  3.74524999e-05,  4.82893501e-03,\n",
       "        -4.86638751e-03],\n",
       "       [ 2.55360985e-02, -7.35329618e-05, -1.85709385e-02,\n",
       "         1.98253223e-04, -1.28574546e-04, -1.29294649e-05,\n",
       "        -6.91882914e-04, -3.83733149e-04, -4.23965010e-03,\n",
       "        -3.75596155e-05,  1.34691344e-01,  9.78986387e-01,\n",
       "        -1.35346329e-01, -5.85393497e-02, -1.03636699e-02,\n",
       "         6.26097091e-04,  1.18581598e-02, -3.37053056e-04,\n",
       "         2.11207965e-04, -3.68252246e-04,  1.92461695e-04,\n",
       "        -1.32502459e-03, -1.09779537e-02, -2.03512358e-03,\n",
       "         2.15548064e-03, -4.13908523e-03,  1.38439940e-02,\n",
       "        -9.70490880e-03],\n",
       "       [-6.78672824e-02, -1.82322206e-04,  9.96472370e-01,\n",
       "        -4.71011093e-03, -3.46514470e-03, -1.69222535e-05,\n",
       "        -1.64283545e-04, -1.72984053e-04, -3.95696832e-04,\n",
       "        -2.57382731e-03,  3.91467188e-02,  1.58474945e-02,\n",
       "         2.71247032e-03,  3.64044298e-04,  1.12535431e-02,\n",
       "        -2.26539427e-03,  3.88001970e-03, -1.02021423e-03,\n",
       "        -2.64728285e-03,  3.15234484e-03,  2.14751962e-03,\n",
       "         7.67464022e-04,  5.23551783e-03, -8.16014269e-03,\n",
       "        -1.08983197e-03, -1.36441958e-02,  1.33408310e-03,\n",
       "         1.23101127e-02],\n",
       "       [ 1.57586002e-03,  4.27114379e-05, -3.66552090e-02,\n",
       "         1.90074353e-04, -2.86087643e-04,  1.95131711e-06,\n",
       "         1.11536094e-03,  5.01982467e-04, -1.21250553e-04,\n",
       "         4.46704253e-04,  9.87620742e-01, -1.42144417e-01,\n",
       "        -1.90403909e-02, -3.69717717e-02,  6.77536885e-03,\n",
       "        -1.77447530e-03,  2.03953825e-02, -2.23711194e-03,\n",
       "        -1.03324024e-03,  4.93003814e-05,  1.23963008e-03,\n",
       "        -1.00681186e-02, -4.45314664e-03, -3.26897879e-03,\n",
       "         1.15075853e-03, -1.40439336e-02,  2.15336137e-02,\n",
       "        -7.48968013e-03],\n",
       "       [-9.32713820e-03, -1.40163089e-05,  3.72743759e-03,\n",
       "         1.44918900e-05, -1.46308329e-04, -5.31681146e-06,\n",
       "        -8.42147846e-03, -1.08908782e-02, -1.94317074e-03,\n",
       "        -1.75383897e-01, -5.81470652e-03,  3.03098514e-03,\n",
       "        -2.73575147e-03,  3.11018709e-03,  1.17415825e-01,\n",
       "         9.62312821e-03,  1.09999308e-01, -2.67291214e-03,\n",
       "         7.67454796e-03,  3.31906977e-03,  7.84760406e-02,\n",
       "        -7.14177770e-01,  4.71681854e-01,  1.96085040e-02,\n",
       "         1.64682292e-02,  3.12468030e-01,  1.26266939e-02,\n",
       "        -3.25094724e-01],\n",
       "       [-1.04041702e-02, -8.57519754e-05,  1.61459160e-02,\n",
       "        -2.83963945e-05,  1.67916138e-03,  1.65017700e-05,\n",
       "        -1.17535477e-02, -1.54873788e-02, -2.31651537e-03,\n",
       "         6.29546559e-02,  1.93890635e-03, -8.44144073e-03,\n",
       "        -6.67029996e-03,  8.26587632e-05,  7.03164284e-02,\n",
       "         4.72997396e-03,  1.14779776e-01, -1.25884467e-02,\n",
       "        -2.91449807e-03, -4.30588510e-03, -1.01729846e-01,\n",
       "         3.15497416e-01, -3.52319154e-01,  1.92912216e-02,\n",
       "         1.95594419e-02,  6.04605828e-01,  8.93813600e-03,\n",
       "        -6.13543964e-01],\n",
       "       [-2.71986150e-03, -2.50792679e-05,  3.72214481e-03,\n",
       "        -7.72496018e-05,  1.60074701e-03, -3.93091404e-06,\n",
       "        -6.16026642e-04,  5.82709907e-04,  8.44723581e-04,\n",
       "        -8.79048475e-02, -1.42585854e-02, -1.23705117e-02,\n",
       "        -2.53540599e-03,  1.25004601e-02, -2.91848141e-01,\n",
       "         3.02869130e-02,  3.57985817e-01,  9.62863997e-03,\n",
       "         2.97086968e-02,  2.32844505e-02,  4.86102025e-01,\n",
       "        -3.76842693e-01, -6.23926774e-01,  3.66001039e-02,\n",
       "         2.71728213e-02, -5.95468355e-02,  7.66444753e-03,\n",
       "         5.18823880e-02],\n",
       "       [-6.93426291e-04, -4.45909912e-06, -1.17807119e-02,\n",
       "        -3.42815204e-05,  2.32989455e-04,  6.44233485e-06,\n",
       "        -3.03465085e-03, -3.40183696e-03,  4.38109360e-04,\n",
       "        -5.29361607e-03, -6.65138961e-03,  9.34828099e-03,\n",
       "         2.04294674e-04,  3.88627927e-03,  9.33054982e-01,\n",
       "         2.16841005e-03, -2.73702306e-02, -3.70904782e-03,\n",
       "         8.11383744e-03, -5.39731842e-03,  2.61822221e-01,\n",
       "        -3.33872997e-02, -2.11957147e-01,  1.27237716e-02,\n",
       "        -3.00719664e-03, -7.81645803e-02, -7.19860717e-03,\n",
       "         8.53631875e-02],\n",
       "       [-3.36878923e-04, -3.27362295e-05,  5.27231267e-03,\n",
       "         1.15873441e-05,  5.90726687e-04,  5.79494204e-07,\n",
       "        -3.06000026e-03, -3.74171440e-03,  1.90058096e-04,\n",
       "         1.51683654e-02,  1.90772126e-02,  5.86378170e-03,\n",
       "         4.83171873e-03,  3.43515222e-03, -1.57359828e-01,\n",
       "        -7.67903919e-03, -7.32464197e-01, -8.93097146e-03,\n",
       "        -1.16214297e-02, -5.29228015e-03,  6.27588517e-01,\n",
       "         8.23737801e-02,  6.51529709e-02, -7.65763391e-03,\n",
       "        -1.46971571e-03,  1.34809993e-01, -1.49741758e-02,\n",
       "        -1.19835817e-01],\n",
       "       [-8.60178323e-03, -2.24872526e-06,  7.86755973e-03,\n",
       "        -1.47369862e-05, -5.79616278e-04,  1.39501236e-05,\n",
       "         9.78593636e-04,  1.29623165e-04, -3.62698750e-06,\n",
       "        -7.56765635e-02,  8.11351946e-03,  1.26883992e-03,\n",
       "        -1.51093784e-03,  8.45185788e-04,  9.68679985e-03,\n",
       "         2.57532014e-01, -4.36993037e-01,  6.85460652e-02,\n",
       "         2.65287110e-01,  1.29392672e-01, -4.12205258e-01,\n",
       "        -2.91571692e-01, -3.16946010e-01,  4.60540779e-01,\n",
       "         2.76417357e-01, -8.76388077e-03, -1.64277227e-02,\n",
       "         2.51916035e-02],\n",
       "       [-2.07675229e-03, -1.34989469e-05,  3.93509606e-03,\n",
       "        -1.75356830e-05,  5.90605264e-05,  9.90493209e-07,\n",
       "        -4.65807079e-03, -5.33510294e-03, -2.35419304e-04,\n",
       "         3.30823086e-02,  1.81278102e-03,  2.35576756e-03,\n",
       "         9.48913601e-04, -2.17293899e-03, -1.08505855e-02,\n",
       "        -3.00666866e-01,  7.36493941e-02, -2.19831880e-02,\n",
       "        -2.86304274e-01, -6.55084582e-02,  6.94644903e-02,\n",
       "         5.37290480e-02,  6.42287264e-02,  8.06192976e-01,\n",
       "        -3.92801848e-01, -6.05598997e-03,  3.70667415e-03,\n",
       "         2.34931582e-03],\n",
       "       [-2.10342193e-03,  1.16237757e-05, -1.12895843e-03,\n",
       "         1.84216305e-05,  3.17234287e-04, -5.91715203e-06,\n",
       "        -5.29497409e-03, -5.99171051e-03, -1.28914767e-04,\n",
       "         3.72417154e-02, -2.38849874e-03, -6.42971434e-04,\n",
       "         4.79455267e-04,  4.68784627e-04,  3.05742387e-03,\n",
       "        -5.24836484e-01,  1.51578231e-02,  2.85703623e-03,\n",
       "        -3.36285392e-01, -1.28675097e-02,  1.13337005e-02,\n",
       "        -9.74053281e-04,  8.98715319e-03,  5.83905826e-02,\n",
       "         7.78237143e-01, -1.01548010e-02, -3.73533713e-03,\n",
       "         1.38901381e-02],\n",
       "       [ 1.84362427e-03,  6.27739306e-06,  5.63420556e-04,\n",
       "        -2.80742023e-05, -4.54709596e-05,  6.44686515e-07,\n",
       "         3.17300451e-03,  3.11010504e-03,  9.97626826e-05,\n",
       "        -2.72469050e-02, -1.18070337e-04,  2.13665373e-04,\n",
       "        -8.70847207e-04, -2.47359813e-04, -4.34283778e-03,\n",
       "        -6.40917866e-01, -1.11071424e-03, -7.10070027e-03,\n",
       "         7.60115825e-01, -2.54696816e-04,  6.25491067e-04,\n",
       "         7.57294080e-03, -3.90579556e-04, -1.76982720e-02,\n",
       "        -1.00841428e-01,  5.92915098e-03,  3.96527223e-05,\n",
       "        -5.96880371e-03],\n",
       "       [ 3.88901312e-03,  1.99243153e-05,  3.56759377e-03,\n",
       "        -1.48584198e-05, -3.26012950e-04,  3.84537822e-06,\n",
       "         9.74554156e-03,  1.46579600e-02,  5.15082329e-04,\n",
       "         9.51209884e-01, -2.02561732e-03,  1.18474695e-04,\n",
       "         1.24599575e-03, -6.24350008e-04, -2.11694393e-04,\n",
       "         1.11480486e-02,  2.60027392e-03,  2.07696546e-01,\n",
       "         4.45026070e-02, -2.94011350e-02,  6.74312272e-03,\n",
       "        -2.18743361e-01,  6.05762385e-03, -1.15450093e-02,\n",
       "        -1.90587167e-02,  1.14743458e-02,  1.90996605e-03,\n",
       "        -1.33843118e-02],\n",
       "       [ 1.37538908e-03,  2.14346741e-05, -4.15749638e-03,\n",
       "         3.65458472e-05, -4.93605539e-05,  3.26449146e-07,\n",
       "         1.60996801e-02,  1.83198436e-02,  1.71742414e-04,\n",
       "         2.76341746e-03, -2.30921723e-04,  7.21482719e-04,\n",
       "         3.76423515e-04, -6.05650108e-04,  1.09182220e-02,\n",
       "        -2.01290729e-01, -7.17102604e-02,  8.10165193e-02,\n",
       "        -1.96974938e-01,  9.15925208e-01, -6.84993560e-02,\n",
       "        -6.22756909e-02, -6.41176495e-02, -1.39951312e-01,\n",
       "        -1.92121792e-01,  6.65883357e-03,  2.61951839e-03,\n",
       "        -9.27835196e-03],\n",
       "       [ 1.21016433e-03, -2.69825654e-06,  4.02587653e-04,\n",
       "         3.16225219e-06,  2.83255037e-04, -2.75756048e-06,\n",
       "         1.33900829e-02,  1.24757213e-02,  4.15541231e-06,\n",
       "        -2.08057310e-01,  2.19842427e-03, -4.60247001e-05,\n",
       "         9.89730641e-04,  1.15541691e-03,  4.96424494e-03,\n",
       "        -1.23419433e-01, -7.83459031e-02,  9.18565571e-01,\n",
       "        -1.21571906e-01, -1.94933070e-01, -7.08425168e-02,\n",
       "        -2.37318205e-02, -7.65655782e-02, -1.08912958e-01,\n",
       "        -1.20242385e-01, -6.13510332e-04,  1.85682607e-02,\n",
       "        -1.79547504e-02],\n",
       "       [ 4.03926675e-04, -2.73812262e-06, -3.56320169e-04,\n",
       "        -2.12611714e-06,  5.87156223e-05, -1.06166678e-08,\n",
       "         3.25535279e-02,  3.72027783e-02, -1.40061525e-04,\n",
       "         3.40041276e-03, -2.83145446e-02, -1.35748670e-02,\n",
       "        -3.17665080e-03, -3.08495123e-03,  5.89461842e-03,\n",
       "         7.21355154e-03, -2.76303938e-02, -2.13115469e-02,\n",
       "         7.76963732e-03,  3.08942389e-03,  2.78664304e-03,\n",
       "         7.88628633e-03, -2.52828417e-03,  8.68355571e-03,\n",
       "         1.40411270e-02, -4.16422460e-01,  8.14306943e-01,\n",
       "        -3.97884483e-01],\n",
       "       [ 3.25966200e-03,  1.03227376e-06,  9.19381019e-04,\n",
       "        -8.68274673e-06,  2.64066708e-04,  6.67180880e-07,\n",
       "         7.26167474e-01,  6.84319521e-01,  3.61479860e-04,\n",
       "        -1.32132100e-02,  3.30964848e-04,  1.44875972e-03,\n",
       "         4.32243913e-04, -9.27395485e-04,  5.74118608e-03,\n",
       "         3.15708238e-03,  5.56438053e-03, -2.18342446e-02,\n",
       "        -2.39520766e-03, -1.91142941e-02,  6.96771799e-03,\n",
       "         2.42899983e-03,  2.71968419e-03,  1.17280589e-02,\n",
       "         1.07778224e-02,  3.62579492e-02, -4.03646022e-02,\n",
       "         4.10665304e-03],\n",
       "       [ 6.15436578e-04,  1.98765988e-06,  1.09073411e-04,\n",
       "        -2.92826974e-07,  8.20237933e-05, -6.35978206e-07,\n",
       "        -6.86142171e-01,  7.27425051e-01,  8.44331831e-05,\n",
       "        -3.92194138e-03,  5.31991004e-04, -1.94655145e-04,\n",
       "         7.20083408e-05,  8.36422030e-06,  9.50992817e-04,\n",
       "        -8.40570177e-06, -7.35313466e-05, -8.52740964e-04,\n",
       "        -1.53672838e-04, -2.02744997e-03, -1.47453877e-04,\n",
       "         6.68022136e-04,  3.61508982e-04,  1.25527015e-03,\n",
       "         9.78453431e-04,  4.61712773e-03, -3.84539775e-03,\n",
       "        -7.71729977e-04],\n",
       "       [-0.00000000e+00, -4.56533692e-19,  3.85968550e-18,\n",
       "         3.14008430e-19, -7.57359998e-18,  1.35943888e-19,\n",
       "         1.17836338e-14, -1.15945263e-14,  3.99860995e-18,\n",
       "         2.26833059e-15,  1.67899782e-16,  1.08815724e-16,\n",
       "         6.05790272e-17, -4.04250517e-19, -2.63912383e-17,\n",
       "         5.21470556e-02,  5.21470556e-02,  5.21470556e-02,\n",
       "         5.21470556e-02,  5.21470556e-02,  5.21470556e-02,\n",
       "         5.21470556e-02,  5.21470556e-02,  5.21470556e-02,\n",
       "         5.21470556e-02, -5.69446177e-01, -5.69446177e-01,\n",
       "        -5.69446177e-01],\n",
       "       [-0.00000000e+00,  1.33560389e-20,  1.26093992e-17,\n",
       "        -1.03612226e-20, -7.66360915e-19,  5.39259560e-21,\n",
       "         3.26289903e-16, -6.59669905e-16, -5.22551224e-19,\n",
       "         2.12151394e-16,  3.33507186e-17,  4.90003750e-17,\n",
       "         2.01176737e-17, -1.20024229e-17, -3.22495830e-17,\n",
       "        -3.11898516e-01, -3.11898516e-01, -3.11898516e-01,\n",
       "        -3.11898516e-01, -3.11898516e-01, -3.11898516e-01,\n",
       "        -3.11898516e-01, -3.11898516e-01, -3.11898516e-01,\n",
       "        -3.11898516e-01, -9.52070623e-02, -9.52070623e-02,\n",
       "        -9.52070623e-02]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(svd_solver='randomized', random_state=42)\n",
    "ypca=pca.fit(d)\n",
    "ypca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98773504 0.00754396]\n",
      "[212713.93818615  18589.83484462]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98773504]\n",
      "[212713.93818615]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=df2.drop([\"Revenue\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>Administrative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.033063</td>\n",
       "      <td>0.965554</td>\n",
       "      <td>Administrative_Duration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>Informational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025668</td>\n",
       "      <td>0.256994</td>\n",
       "      <td>Informational_Duration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019988</td>\n",
       "      <td>-0.006551</td>\n",
       "      <td>ProductRelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2                  Feature\n",
       "0  0.000651  0.009996           Administrative\n",
       "1  0.033063  0.965554  Administrative_Duration\n",
       "2  0.000258  0.002060            Informational\n",
       "3  0.025668  0.256994   Informational_Duration\n",
       "4  0.019988 -0.006551           ProductRelated"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = list(d)\n",
    "pcs_df = pd.DataFrame({'PC1':pca.components_[0],'PC2':pca.components_[1], 'Feature':colnames})\n",
    "pcs_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (10,5))\n",
    "plt.scatter(pcs_df.PC1, pcs_df.PC2)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "for i, txt in enumerate(pcs_df.Feature):\n",
    "    plt.annotate(txt, (pcs_df.PC1[i],pcs_df.PC2[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.87735078e-01, 7.54396457e-03, 4.48200627e-03, 1.37701432e-04,\n",
       "       9.21305220e-05, 4.37862568e-06, 1.63146144e-06, 1.55387926e-06,\n",
       "       7.77478036e-07, 2.36453713e-07, 2.02480465e-07, 7.35094603e-08,\n",
       "       5.99353621e-08, 5.00480466e-08, 4.74734903e-08, 3.81317577e-08,\n",
       "       1.75981410e-08, 1.11132995e-08, 9.61419395e-09, 9.42265540e-09,\n",
       "       8.03155655e-09, 6.66290871e-09, 4.05650868e-09, 2.16141020e-09,\n",
       "       1.02166164e-09, 4.89364841e-11, 8.31726211e-33, 8.31726211e-33])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'cumulative explained variance')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Making the screeplot - plotting the cumulative variance against the number of components\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa=df2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvectors \n",
      "[[ 6.51350415e-04  9.99094564e-03 -8.57775746e-04 -3.52893093e-02\n",
      "   6.50912316e-03 -1.76684364e-02 -9.68154583e-01 -2.35378086e-01\n",
      "   2.54425265e-02 -6.79642623e-02 -1.62897679e-03 -9.39701883e-03\n",
      "  -1.02939705e-02 -1.95427097e-03  5.22377249e-04  6.22086386e-04\n",
      "  -4.54209476e-03  8.11076555e-03 -2.14036807e-03  2.20034388e-03\n",
      "  -1.95638127e-03 -1.22829945e-03 -1.95589243e-03 -3.13231315e-04\n",
      "   2.00459101e-04 -7.99435171e-16  3.58768680e-16  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 3.30306576e-02  9.65592115e-01 -2.57665351e-01 -3.65301394e-03\n",
      "  -5.95603361e-03  2.22084630e-04  9.76104231e-03  2.28308320e-03\n",
      "  -7.32471589e-05 -1.82065770e-04 -4.23728978e-05 -1.17473207e-05\n",
      "  -8.66324132e-05 -2.36469856e-05  4.17242204e-06  3.28317447e-05\n",
      "   1.25876204e-05  1.00051419e-06 -1.42634152e-05 -1.09659680e-05\n",
      "  -6.71548894e-06 -2.15238216e-05 -2.39630650e-06 -7.51787649e-06\n",
      "  -3.03538570e-06 -2.32953324e-18  1.03415300e-18  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 2.57873620e-04  2.05928167e-03  4.44372700e-03 -5.92583766e-03\n",
      "   5.68942618e-04 -4.48156187e-03 -6.51172558e-02 -2.19695711e-02\n",
      "  -1.85780379e-02  9.96475170e-01  3.63608245e-02  4.45016974e-03\n",
      "   1.57670406e-02  4.43918262e-03  1.16302887e-02 -4.97303377e-03\n",
      "  -3.73180517e-03 -8.28545400e-03  3.82889869e-03  1.24723044e-03\n",
      "  -6.72976585e-04  4.24259644e-03 -1.12064089e-03 -8.20231936e-04\n",
      "  -4.56673089e-04  1.08880375e-14 -4.82233632e-15  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 2.56456704e-02  2.56860832e-01  9.66073039e-01 -6.19310009e-03\n",
      "  -1.19932157e-03  5.10202938e-04  2.13719821e-03  9.04094974e-04\n",
      "   1.97975078e-04 -4.70866080e-03 -1.88955497e-04  1.46759017e-05\n",
      "  -3.06892004e-05 -7.56633504e-05  3.41443828e-05 -9.93774006e-06\n",
      "  -1.96046539e-05  1.48440231e-05 -1.70823281e-05 -1.85683343e-05\n",
      "   2.86855925e-05 -3.66160286e-05 -9.35092391e-07 -5.88415973e-06\n",
      "  -1.86272053e-06 -5.18277751e-17  2.31477181e-17  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 1.99883702e-02 -6.58287805e-03 -5.34627051e-03 -9.97667306e-01\n",
      "  -5.39361318e-02  5.19954063e-03  3.35842601e-02  1.02793431e-02\n",
      "  -1.30140120e-04 -3.46833217e-03  2.80486577e-04 -2.55746994e-04\n",
      "   1.75323166e-03  1.56861212e-03 -2.36763975e-04 -5.89146172e-04\n",
      "  -3.70686972e-04  5.81348091e-04  7.40786179e-05 -3.31530501e-04\n",
      "   5.93397089e-05  6.19114937e-05 -1.88896479e-04  1.49105889e-04\n",
      "   4.93076369e-05 -2.54961461e-17  6.73124731e-18  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 9.98924924e-01 -3.84010060e-02 -1.61755810e-02  2.02941740e-02\n",
      "   8.18113823e-04 -3.17968453e-05 -4.16513448e-04 -1.08456185e-04\n",
      "  -1.29670266e-05 -1.70261509e-05 -2.06875704e-06 -4.87017493e-06\n",
      "   1.64476304e-05 -3.21315729e-06 -6.66448220e-06 -6.66916500e-08\n",
      "  -8.60152108e-06 -1.46410112e-05  9.07550698e-07  6.06587660e-06\n",
      "  -8.21047329e-07 -1.70038734e-07  1.96036636e-06 -1.38207910e-06\n",
      "  -1.44673597e-07 -4.01831441e-19  2.39228196e-19  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 4.84909953e-04  5.67780984e-03 -6.45931213e-04 -5.37206447e-02\n",
      "   9.98434748e-01 -3.79092042e-03  8.82930778e-03 -1.05390999e-04\n",
      "  -4.28608630e-03 -4.08154692e-04  1.50752250e-05 -3.15008140e-03\n",
      "  -2.20148904e-03  1.96826760e-03 -7.27125627e-04  3.27819138e-04\n",
      "  -8.87089140e-03 -5.20620943e-04 -2.12825291e-04  1.55689361e-04\n",
      "  -1.21346751e-04 -3.26892174e-05 -6.06962453e-06 -9.22887578e-05\n",
      "  -2.05063429e-04 -5.81658001e-17  3.62763250e-18  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-2.50022218e-07 -1.77825751e-05 -4.82922962e-06 -9.90619158e-05\n",
      "  -1.48406827e-04  1.93451917e-04  6.42946752e-04  3.37417493e-04\n",
      "  -5.81883720e-04 -1.03707066e-04  1.02450153e-04 -2.81785257e-02\n",
      "   1.75659935e-02 -3.55964023e-02 -5.38747456e-02  8.33010165e-03\n",
      "  -2.57389874e-03  1.22618021e-02  5.46198353e-04 -3.50437158e-03\n",
      "   2.82553603e-03 -4.11528634e-03 -8.85541112e-02 -9.92882168e-01\n",
      "  -2.83930095e-02  8.54358249e-15  1.22163174e-15  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 1.39437103e-06 -5.90664454e-05 -5.82364901e-05 -1.34618276e-04\n",
      "   9.54791911e-04  4.65425993e-02 -6.79933696e-03  3.43892290e-02\n",
      "   1.34683513e-01  3.88942131e-02 -9.87559653e-01 -3.16975548e-03\n",
      "   1.77995838e-03 -1.64474441e-02  7.31436547e-03 -1.96987749e-02\n",
      "   9.41314155e-03 -7.31889035e-03  1.84570599e-03  2.30082774e-03\n",
      "   1.59383186e-04  5.83580805e-05 -1.90361748e-03  8.35717912e-04\n",
      "  -2.82315857e-02  5.58874879e-16  3.15740720e-17  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-6.67955605e-06 -1.69703381e-04 -1.74295358e-04  9.57807550e-04\n",
      "   4.53704703e-03  5.96418595e-02 -8.26670304e-03  1.30098223e-01\n",
      "   9.78990908e-01  1.58862546e-02  1.42116186e-01  2.81784672e-03\n",
      "  -8.85375237e-03 -1.15690519e-02 -9.43367885e-03 -5.55893575e-03\n",
      "  -4.45242804e-03 -1.48432817e-03  2.37434550e-03  6.39282805e-04\n",
      "  -2.20042058e-04 -6.57319407e-04  5.95856671e-05  5.11350447e-04\n",
      "  -1.36357189e-02  6.24300299e-16 -6.35801060e-17  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-4.15022274e-05  4.40968541e-05 -3.46729683e-04  2.01410970e-03\n",
      "   1.89971298e-03  4.44766127e-02 -2.38067351e-01  9.60495784e-01\n",
      "  -1.35334697e-01  2.73252181e-03  1.90656752e-02 -2.40644372e-03\n",
      "  -6.72075672e-03 -2.59239303e-03 -1.17103687e-04 -4.89632422e-03\n",
      "   1.31389784e-03  1.49881651e-03  9.03895559e-04 -4.30741479e-04\n",
      "   8.44692457e-04 -3.85735622e-04 -1.24252845e-03  4.91814484e-04\n",
      "  -3.17641726e-03  2.69325315e-16 -3.98899947e-17  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-7.64946233e-05 -9.34430987e-05 -3.78374227e-04  4.23147306e-03\n",
      "   3.79757971e-03  9.95853368e-01 -6.22110355e-03 -5.66421817e-02\n",
      "  -5.85352816e-02  3.68105722e-04  3.69693645e-02  2.09620690e-03\n",
      "   4.06309691e-04  1.23598273e-02 -3.95492508e-03 -3.57105761e-03\n",
      "   1.24147952e-03 -7.52115003e-04 -2.16451915e-03 -4.78326592e-04\n",
      "   2.63429562e-04  5.67078647e-04 -1.00386727e-03  5.95180325e-05\n",
      "  -3.02592577e-03 -3.96695562e-16  8.04032150e-17  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 1.62948687e-06  4.34917832e-05  5.98838404e-05 -3.93364896e-04\n",
      "   2.13328065e-04 -2.66075327e-04 -2.44028337e-03 -1.27725330e-03\n",
      "  -1.03638475e-02  1.12641266e-02 -6.69973683e-03  1.26069439e-01\n",
      "   6.14876911e-02 -2.90665276e-01 -9.31198126e-01  1.55798549e-01\n",
      "  -1.37783151e-02 -1.12329833e-02 -1.07461902e-02 -2.82235569e-03\n",
      "   4.21103640e-03 -1.02827683e-02  8.26188278e-04  5.94430994e-02\n",
      "   7.22353489e-03 -9.43440018e-16 -7.88513007e-17  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 2.87972475e-05  9.42198748e-05  1.17000982e-05 -1.23107082e-03\n",
      "   9.37475131e-03 -5.89446198e-04 -4.35988938e-03 -2.92005930e-03\n",
      "   1.26521401e-03  2.84388227e-03  1.20737723e-02  1.20653166e-01\n",
      "  -4.28245027e-03 -1.23599670e-01  2.98196072e-02 -5.80251307e-02\n",
      "   9.81007232e-01  5.34570881e-02 -4.24611109e-03 -1.12666374e-03\n",
      "   6.80522480e-04 -1.41612391e-02 -1.19006866e-02 -2.06466881e-03\n",
      "   4.43513911e-03  1.61339236e-15 -4.26557750e-16  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 7.53830839e-07  2.77597107e-05 -1.47311460e-05 -3.47778261e-04\n",
      "  -4.26364797e-05 -1.14707275e-03 -2.21267058e-03  3.39701068e-04\n",
      "   6.26378822e-04 -2.26132674e-03  1.78071573e-03  7.91425273e-03\n",
      "   5.48484492e-03  2.92885236e-02 -2.17792041e-03  6.82592364e-03\n",
      "   2.03528118e-02 -2.56904626e-01 -3.01307190e-01  5.32845611e-01\n",
      "   6.34548263e-01  2.00874849e-01  1.20639642e-01 -1.62393725e-02\n",
      "   6.20200198e-03  5.82495309e-02  3.10123128e-01  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-3.17846817e-06  1.01663958e-05  4.54632613e-05  5.41422966e-04\n",
      "   4.54568040e-04  1.07013757e-04 -1.10282226e-03  6.77074793e-03\n",
      "   1.18529371e-02  3.83623104e-03 -2.04900004e-02  9.64094119e-02\n",
      "   1.19148783e-01  3.64997333e-01  2.07278970e-02  7.29771948e-01\n",
      "   5.60171121e-02  4.35429238e-01  7.32933288e-02 -1.52046091e-02\n",
      "   1.27360075e-03  7.08596665e-02  7.36014141e-02 -9.44461588e-03\n",
      "  -2.82429219e-02  5.82495309e-02  3.10123128e-01  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-2.95300622e-06 -2.23695965e-05 -2.41487962e-06  1.91614697e-04\n",
      "  -1.75874374e-04 -1.28405291e-03  1.83981562e-03 -7.83091334e-04\n",
      "  -3.37658737e-04 -1.01806274e-03  2.22145339e-03 -2.34262894e-03\n",
      "  -1.30122926e-02  1.18134667e-02  3.18404123e-03  9.52071048e-03\n",
      "  -6.16247127e-03 -7.41550113e-02 -2.59046566e-02  2.93967333e-03\n",
      "   2.70742269e-03 -7.82044769e-02 -9.38138379e-01  8.28638881e-02\n",
      "  -1.62204852e-02  5.82495309e-02  3.10123128e-01  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 2.20390189e-07 -4.76681459e-08  2.26999880e-05 -2.85780053e-04\n",
      "  -2.09765914e-04 -7.37234184e-04 -1.94419141e-04  1.86871864e-03\n",
      "   2.12368017e-04 -2.64694752e-03  1.03855433e-03  5.51349222e-03\n",
      "  -1.96681852e-03  2.85984984e-02 -8.08800614e-03  1.06508866e-02\n",
      "   2.20373303e-02 -2.64230010e-01 -2.85954670e-01  3.30541579e-01\n",
      "  -7.64956958e-01  1.96263344e-01  1.16367156e-01 -1.89005703e-02\n",
      "   6.98046437e-03  5.82495309e-02  3.10123128e-01  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 1.11968224e-07 -2.11396474e-05 -1.16387481e-05 -1.66470846e-04\n",
      "  -1.76239673e-04  2.29345410e-04 -3.96884794e-04  7.40328132e-05\n",
      "  -3.68371830e-04  3.14422673e-03 -6.46573628e-05  1.18762341e-03\n",
      "  -3.48531850e-03  2.33011866e-02  5.13724723e-03  5.17727497e-03\n",
      "  -1.21484952e-03 -1.29674687e-01 -6.48846376e-02  1.21884574e-02\n",
      "   6.61615428e-04 -9.16672812e-01  1.93986472e-01 -1.64490315e-02\n",
      "   3.69073491e-03  5.82495309e-02  3.10123128e-01  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.61277193e-05  2.53185758e-05  4.70026826e-05  1.30240662e-03\n",
      "  -6.92187247e-04 -9.01111548e-03  2.40508840e-03 -1.98120263e-03\n",
      "   1.90157812e-04  2.07778359e-03 -1.32986757e-03  5.47018070e-02\n",
      "  -9.40310296e-02  4.88611084e-01 -2.64110120e-01 -6.30887240e-01\n",
      "   4.87599915e-03  4.09316348e-01  6.91431693e-02 -1.12857015e-02\n",
      "  -5.89561039e-04  6.80354058e-02  6.54652745e-02 -1.27542158e-02\n",
      "   1.91873798e-03  5.82495309e-02  3.10123128e-01  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.58549905e-05 -4.45082380e-05 -1.07489956e-05  5.53991437e-04\n",
      "  -2.21958465e-04  6.57136237e-03  5.93987480e-03 -5.96210422e-04\n",
      "  -1.32404632e-03  8.40666715e-04  9.84646800e-03 -6.86259613e-01\n",
      "   3.42854092e-01 -4.36894676e-01  4.82296677e-02 -8.92669091e-02\n",
      "   9.10304165e-03  3.10517849e-01  6.15429918e-02 -7.76344709e-03\n",
      "  -1.16569104e-03  6.11376645e-02  6.88382180e-02  3.50508513e-02\n",
      "   9.49408805e-03  5.82495309e-02  3.10123128e-01  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 3.73628002e-05 -8.37650123e-05 -4.32837442e-05 -1.42915463e-03\n",
      "   6.06888779e-04  6.40618397e-03  3.97724777e-03 -4.48374979e-03\n",
      "  -1.09717317e-02  5.26951963e-03  4.85026702e-03  4.88803409e-01\n",
      "  -3.94515395e-01 -5.71428720e-01  2.06745174e-01 -4.90274284e-02\n",
      "  -1.57780819e-01  3.07767703e-01  6.43831134e-02 -8.74470019e-03\n",
      "   2.98424758e-04  6.51088215e-02  7.21433988e-02 -1.43077900e-02\n",
      "  -3.70223335e-03  5.82495309e-02  3.10123128e-01  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-9.24084216e-07  7.55317108e-05 -1.69156654e-05 -3.30432282e-04\n",
      "   3.01848589e-04  5.06829026e-04 -5.96928084e-03 -1.42215987e-03\n",
      "  -2.03552154e-03 -8.15178423e-03  3.28796328e-03  1.83892060e-02\n",
      "   1.97357075e-02  3.52793901e-02 -1.26280647e-02  6.41966093e-03\n",
      "   3.48025173e-02 -4.61565219e-01  8.04982226e-01 -5.94529657e-02\n",
      "   1.90347186e-02  1.40412943e-01  1.07387681e-01 -1.61494509e-02\n",
      "   7.19444039e-03  5.82495309e-02  3.10123128e-01  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 5.89278927e-07  3.30537693e-05 -1.54327531e-05 -2.98196463e-05\n",
      "   1.55356745e-04 -1.64125922e-03 -4.28594899e-03  2.13213609e-04\n",
      "   2.15548836e-03 -1.09030648e-03 -1.14089640e-03  1.56830399e-02\n",
      "   1.97874272e-02  2.64339136e-02  2.98008439e-03  8.15173348e-04\n",
      "   1.79693275e-02 -2.76501586e-01 -3.95293675e-01 -7.76063897e-01\n",
      "   1.08188165e-01  1.92184594e-01  1.19709123e-01 -1.36696924e-02\n",
      "   1.26851728e-02  5.82495309e-02  3.10123128e-01  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-2.08948184e-05  1.38926711e-04 -6.97566894e-05  5.63396433e-04\n",
      "   2.07624005e-03 -2.50253146e-03 -8.38557583e-03  6.46553739e-05\n",
      "  -4.14208479e-03 -1.36085306e-02  1.42431977e-02  3.44070295e-01\n",
      "   5.86546133e-01 -5.22413453e-02  7.77750113e-02 -1.30466717e-01\n",
      "  -5.51383042e-02  5.85751559e-03 -6.06740862e-03  1.04004972e-02\n",
      "  -6.27979909e-03 -5.93292333e-03 -2.03871470e-03  9.48140558e-03\n",
      "  -4.17817647e-01  5.67470975e-01 -1.12895901e-01  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.17445547e-06  2.16641443e-07 -2.95999224e-06  8.32764369e-05\n",
      "   2.65640651e-04  4.31446332e-03 -7.97213009e-04  4.83198405e-03\n",
      "   1.38433699e-02  1.32705118e-03 -2.15341705e-02  1.26000532e-02\n",
      "   8.49039547e-03  8.66934189e-03  6.84074256e-03  1.52359551e-02\n",
      "  -4.29084189e-03  1.59441911e-02  3.76851206e-03  3.71837476e-03\n",
      "  -7.57525836e-05 -2.08250252e-03 -1.71478235e-02 -2.23425394e-02\n",
      "   8.15036011e-01  5.67470975e-01 -1.12895901e-01  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 2.20692739e-05 -1.39143352e-04  7.27166817e-05 -6.46672870e-04\n",
      "  -2.34188070e-03 -1.81193186e-03  9.18278884e-03 -4.89663943e-03\n",
      "  -9.70128512e-03  1.22814794e-02  7.29097279e-03 -3.56670349e-01\n",
      "  -5.95036529e-01  4.35720034e-02 -8.46157539e-02  1.15230762e-01\n",
      "   5.94291461e-02 -2.18017067e-02  2.29889656e-03 -1.41188719e-02\n",
      "   6.35555167e-03  8.01542584e-03  1.91865382e-02  1.28611338e-02\n",
      "  -3.97218363e-01  5.67470975e-01 -1.12895901e-01  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "\n",
      "Eigenvalues \n",
      "[ 3.66976827e+06  2.80018360e+04  1.66416987e+04  5.11573545e+02\n",
      "  3.37935733e+02  1.62687739e+01  6.06792941e+00  5.77384733e+00\n",
      "  2.88874508e+00  8.79076872e-01  7.52420775e-01  2.68516951e-01\n",
      "  2.21816462e-01  1.86297335e-01  1.76941542e-01  1.41832827e-01\n",
      "  9.26460994e-02  6.50967825e-02  4.12753448e-02  3.57111260e-02\n",
      "  3.50054701e-02  2.47304862e-02  1.57594719e-02  1.12855242e-02\n",
      "  8.01628801e-03 -1.47797394e-16 -6.51113629e-17  0.00000000e+00\n",
      "  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "cov_mat = np.cov(dfa.T)\n",
    "\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "print('Eigenvectors \\n%s' %eig_vecs)\n",
    "print('\\nEigenvalues \\n%s' %eig_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues in descending order:\n",
      "3669768.2724332586\n",
      "28001.835991314634\n",
      "16641.698654933974\n",
      "511.57354488067074\n",
      "337.9357326807168\n",
      "16.26877393037425\n",
      "6.067929412761777\n",
      "5.773847331140222\n",
      "2.888745075028919\n",
      "0.8790768720753284\n",
      "0.7524207749588997\n",
      "0.2685169508864037\n",
      "0.2218164620105354\n",
      "0.18629733509919988\n",
      "0.17694154211121368\n",
      "0.14183282681548431\n",
      "0.09264609935696799\n",
      "0.06509678248334468\n",
      "0.04127534476685028\n",
      "0.03571112600535079\n",
      "0.035005470084399894\n",
      "0.02473048622279097\n",
      "0.01575947186767433\n",
      "0.011285524171266452\n",
      "0.00801628800624105\n",
      "1.4779739375934973e-16\n",
      "6.511136291383082e-17\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "print('Eigenvalues in descending order:')\n",
    "for i in eig_pairs:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api                      as     sm\n",
    "import scipy.stats                          as     stats\n",
    "from   patsy                                import dmatrices\n",
    "from   statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =\"Administrative + Administrative_Duration + Informational + Informational_Duration + ProductRelated + ProductRelated_Duration + BounceRates + ExitRates + PageValues + SpecialDay + OperatingSystems + Browser + Region  + TrafficType + Weekend + Month_Aug  +  Month_Dec + Month_Feb + Month_Jul + Month_June + Month_Mar + Month_May + Month_Nov + Month_Oct + Month_Sep + VisitorType_New_Visitor + VisitorType_Other + VisitorType_Returning_Visitor\"\n",
    "y, X = dmatrices('Revenue ~' + features, df2, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1543: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "C:\\Users\\Amir\\Anaconda3\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:181: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    VIF Factor                       features\n",
      "0     0.000000                      Intercept\n",
      "1     1.012325                Weekend[T.True]\n",
      "2     1.959938                 Administrative\n",
      "3     1.692911        Administrative_Duration\n",
      "4     1.835911                  Informational\n",
      "5     1.681260         Informational_Duration\n",
      "6     4.502195                 ProductRelated\n",
      "7     4.348421        ProductRelated_Duration\n",
      "8     6.414579                    BounceRates\n",
      "9     7.164583                      ExitRates\n",
      "10    1.058246                     PageValues\n",
      "11    1.332347                     SpecialDay\n",
      "12    1.172725               OperatingSystems\n",
      "13    1.143916                        Browser\n",
      "14    1.026887                         Region\n",
      "15    1.089245                    TrafficType\n",
      "16         inf                      Month_Aug\n",
      "17         inf                      Month_Dec\n",
      "18         inf                      Month_Feb\n",
      "19         inf                      Month_Jul\n",
      "20         inf                     Month_June\n",
      "21         inf                      Month_Mar\n",
      "22         inf                      Month_May\n",
      "23         inf                      Month_Nov\n",
      "24         inf                      Month_Oct\n",
      "25         inf                      Month_Sep\n",
      "26         inf        VisitorType_New_Visitor\n",
      "27         inf              VisitorType_Other\n",
      "28         inf  VisitorType_Returning_Visitor\n"
     ]
    }
   ],
   "source": [
    "vif               = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"]   = X.columns\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appying Artifial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=10, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=42, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Perceptron(random_state=42,\n",
    "              max_iter=10,\n",
    "              tol=0.001)\n",
    "p.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=p.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for MLP : [[3021   56]\n",
      " [ 439  183]]\n",
      "Accuracy score for MLP : 0.8661800486618005\n",
      "Classification Report for MLP                precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.98      0.92      3077\n",
      "        True       0.77      0.29      0.43       622\n",
      "\n",
      "    accuracy                           0.87      3699\n",
      "   macro avg       0.82      0.64      0.67      3699\n",
      "weighted avg       0.86      0.87      0.84      3699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pcm=confusion_matrix(y_test,ypred)\n",
    "print(\"Confusion matrix for MLP :\",pcm)\n",
    "acc=accuracy_score(y_test,ypred)\n",
    "print(\"Accuracy score for MLP :\",acc)\n",
    "crp=classification_report(y_test,ypred)\n",
    "print(\"Classification Report for MLP \",crp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "print(clf.fit(x_train, y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights between input and first hidden layer:\n",
      "[[-0.07104979  0.17362793 -0.4263037  -0.19840715 -0.24463963]\n",
      " [-0.41937207 -0.26417268 -0.1317062  -0.19643744 -0.09230906]\n",
      " [-0.07469887  0.16678832 -0.25741198  0.32251902 -0.39433651]\n",
      " [ 0.05180562  0.00917996 -0.02205252 -0.30667891 -0.3768304 ]\n",
      " [ 0.23341575  0.45731883 -0.16987622  0.29531667  0.31352297]\n",
      " [ 0.2223563  -0.25499593 -0.39309522 -0.01389951  0.3036024 ]\n",
      " [-0.34289265 -0.05906742  0.38862739  0.0449373   0.15902047]\n",
      " [-0.1583431   0.16925024  0.28333593 -0.39040839  0.2068696 ]\n",
      " [ 0.41690195  0.21163629 -0.18723791  0.24983075 -0.33836985]\n",
      " [-0.04485999  0.35428893 -0.17737133 -0.16879162 -0.32122431]\n",
      " [-0.43158689  0.23620001 -0.26218479 -0.03102614 -0.04329175]\n",
      " [-0.39795954  0.19972441 -0.31700629  0.36253105  0.08793921]\n",
      " [-0.36069661  0.11866438  0.08754544  0.3013784  -0.37009336]\n",
      " [-0.04592075  0.05172805 -0.02173015  0.19819761  0.11691659]\n",
      " [ 0.34324316 -0.29508101 -0.30859856  0.29267591 -0.08577726]\n",
      " [-0.28567273  0.36551936 -0.1299489   0.21686393  0.18886654]\n",
      " [ 0.32227678  0.12197688  0.21308247 -0.10228371 -0.19419167]\n",
      " [ 0.33761275 -0.05740396  0.39630418  0.14749668  0.10141172]\n",
      " [-0.32854559  0.38607781 -0.04267247  0.07239901 -0.07553178]\n",
      " [-0.22545957  0.34943413  0.0628018  -0.41339216  0.09426074]\n",
      " [-0.14868523  0.05190005  0.32755139 -0.06292983  0.32034694]\n",
      " [ 0.10445694 -0.39168126  0.36024296  0.2084981   0.40159525]\n",
      " [-0.28140803 -0.33028446  0.36663685  0.12668293 -0.35278458]\n",
      " [ 0.21785953  0.21751664  0.36051872  0.18332309 -0.32606254]\n",
      " [-0.40944741 -0.40332413 -0.4022614  -0.21737806  0.32253958]\n",
      " [ 0.03051878  0.05318097  0.28922223 -0.31323129 -0.17806883]\n",
      " [ 0.07313572  0.40264333  0.05204672 -0.40670991  0.25607134]\n",
      " [-0.23478449  0.31210038 -0.10439996  0.4180511   0.17038104]]\n",
      "\n",
      "weights between first hidden and second hidden layer:\n",
      "[[-0.71645714 -0.50788739]\n",
      " [ 0.40590654  0.0892543 ]\n",
      " [-0.89931261 -0.79268608]\n",
      " [ 0.80980718  0.088953  ]\n",
      " [-0.47651618 -0.46230084]]\n"
     ]
    }
   ],
   "source": [
    "print(\"weights between input and first hidden layer:\")\n",
    "print(clf.coefs_[0])\n",
    "print(\"\\nweights between first hidden and second hidden layer:\")\n",
    "print(clf.coefs_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
